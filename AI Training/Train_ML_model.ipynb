{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Python code to train an ML model for article type classification\n",
        "The input dataset should include the following columns:\n",
        "- 'type': The classification label for each article.\n",
        "- 'body': The web scraped body content of the article.\n",
        "- 'title': The article title. Used as a fallback when the body content is empty."
      ],
      "metadata": {
        "id": "Xxggic-Hrcvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "xsJYOmu7okIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAQcp6IIju1Q"
      },
      "outputs": [],
      "source": [
        "# All imports used\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "# Choose the ML model type you prefer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'dataset.csv' with the actual path to your dataset CSV file\n",
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "# View the first few rows of the DataFrame (to check import)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "G-O32DCibnVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update column names to match the dataset format\n",
        "type_col_name = 'Type'   # Column for the initial type classification\n",
        "body_col_name = 'body'   # Column for the web scraped article body content\n",
        "title_col_name = 'Title' # Column for the article title (used as fallback if body is empty)\n",
        "\n",
        "class_col_name = 'class' # Column for the 'fixed type' (regrouped types)"
      ],
      "metadata": {
        "id": "W2H4yoJccpSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imporve data"
      ],
      "metadata": {
        "id": "ZOJM1EPxoqoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regroup types to reduce the number of categories\n",
        "This is done to prevent an excessive number of type classes, which could negatively impact model performance."
      ],
      "metadata": {
        "id": "BSLFcDaUozOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrAmfHKNsGC2"
      },
      "outputs": [],
      "source": [
        "# Update the desired data types and corresponding data names based on your dataset\n",
        "def fix_type(type):\n",
        "  type = str(type)\n",
        "  type = type.lower().strip()\n",
        "  if \"malware\" in type or \"spyware\" in type:\n",
        "    return \"Malware\"\n",
        "  elif \"information\" in type:\n",
        "    return \"Informational\"\n",
        "  elif \"ransomware\" in type:\n",
        "    return \"Ransomware\"\n",
        "  elif \"phishing\" in type:\n",
        "    return \"Phishing\"\n",
        "  elif \"data leak\" in type or \"data breach\" in type or \"data stealing\" in type:\n",
        "    return \"Data leak\"\n",
        "  elif \"ai\" in type:\n",
        "    return \"AI\"\n",
        "  elif \"vulnerability\" in type or \"vulerability\" in type or \"vulnerabilities\" in type:\n",
        "    return \"Vulnerability\"\n",
        "  else:\n",
        "    return \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_LVagVosJbS"
      },
      "outputs": [],
      "source": [
        "# Create a new column with the fixed (regrouped) types\n",
        "data[class_col_name] = data[type_col_name].apply(fix_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCpQ9p-4kD93"
      },
      "outputs": [],
      "source": [
        "# View the first few rows of the DataFrame (to check the new fixed types column)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle empty body content\n",
        "Replace empty body entries with the Title value to provide the ML model with usable data for training."
      ],
      "metadata": {
        "id": "fY0i50D7o4Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace column with empty body with title name\n",
        "data[body_col_name] = data.apply(lambda row: row[title_col_name] if row[body_col_name].strip() == '\" \"' else row[body_col_name], axis=1)\n",
        "data[body_col_name] = data.apply(lambda row: row[title_col_name] if row[body_col_name].strip() == '\"\"' else row[body_col_name], axis=1)"
      ],
      "metadata": {
        "id": "BZglZ2_ROQsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck-LMb2g1ESH"
      },
      "outputs": [],
      "source": [
        "# View the first few rows of the DataFrame (to check the updated body column)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwA5_tvVm7tO"
      },
      "source": [
        "#Set up classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsVJbft1oWcq"
      },
      "source": [
        "## Set up pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "940Xuf6kq1u1"
      },
      "outputs": [],
      "source": [
        "# Create pipeline\n",
        "text_clf = Pipeline([\n",
        "  ('vect', CountVectorizer()),\n",
        "  ('tfidf', TfidfTransformer()),\n",
        "  ('clf', LinearSVC()), # replace with your chosen model\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbbB8rql_mJ6"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing data\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E67RfgU6oT4H"
      },
      "source": [
        "## Train / test / evaluate **(optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTJANwJuoa_e"
      },
      "outputs": [],
      "source": [
        "fold_num = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVuwwtjloLgv"
      },
      "outputs": [],
      "source": [
        "# Method for cross validation with scoring metrics\n",
        "def cross_val (model, x_set, y_set, fold_num) :\n",
        "  # Select scoring / evaluation metrics\n",
        "  scoring = ['accuracy', 'precision_weighted', 'precision_micro', 'precision_macro', 'recall_weighted',\n",
        "             'recall_micro', 'recall_macro', 'f1_weighted', 'f1_micro', 'f1_macro']\n",
        "  # Use cross_validate with the given model, x_set, y_set, fold_num and evaluation metrics\n",
        "  results = cross_validate(estimator=model,\n",
        "                               X=x_set,\n",
        "                               y=y_set,\n",
        "                               cv=fold_num,\n",
        "                               scoring=scoring,\n",
        "                               return_train_score=False)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3OZ_QbRoDBV"
      },
      "outputs": [],
      "source": [
        "def print_results(results):\n",
        "  print(\"Mean Validation Accuracy\", results['test_accuracy'].mean())\n",
        "  print(\"Mean Validation Precision (weighted)\", results['test_precision_weighted'].mean())\n",
        "  print(\"Mean Validation Recall (weighted)\", results['test_recall_weighted'].mean())\n",
        "  print(\"Mean Validation F1 Score (weighted)\", results['test_f1_weighted'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEi8pxXtsqsb"
      },
      "outputs": [],
      "source": [
        "results = cross_val(text_clf, data[body_col_name], data[class_col_name], fold_num)\n",
        "print_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and save model"
      ],
      "metadata": {
        "id": "qTixPphZd4RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "text_clf.fit(data[body_col_name], data[class_col_name])"
      ],
      "metadata": {
        "id": "77DdyVpqf2du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model as pickle file\n",
        "import pickle\n",
        "pickle_file = 'type_ml_model.sav'\n",
        "\n",
        "pickle.dump(text_clf, open(pickle_file, 'wb'))"
      ],
      "metadata": {
        "id": "D7WOpqzXeHRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a JSON file for loading into MongoDB\n",
        "import json\n",
        "from io import BytesIO\n",
        "import base64\n",
        "json_file = 'json_ml_data.json'\n",
        "\n",
        "# Serialize the model to a binary stream using pickle\n",
        "model_binary = BytesIO()\n",
        "pickle.dump(text_clf, model_binary)\n",
        "model_binary.seek(0)  # Rewind the binary stream to the beginning\n",
        "\n",
        "# Convert binary data to base64 string\n",
        "model_base64 = base64.b64encode(model_binary.read()).decode('utf-8')\n",
        "\n",
        "# Create the needed JSON structure\n",
        "json_ml_data = {\n",
        "    'model': model_base64,\n",
        "    'name': \"ML model\" # Retain this name to ensure consistency with the database script for loading\n",
        "}\n",
        "\n",
        "# Convert to JSON\n",
        "with open(json_file, 'w') as f:\n",
        "      json.dump(json_ml_data, f, default=str)  # Use default=str to handle non-serializable types"
      ],
      "metadata": {
        "id": "UzohJEDlxDq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}